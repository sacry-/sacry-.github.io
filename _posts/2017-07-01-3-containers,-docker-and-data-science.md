---
layout: post
author: Matthias Nitsche
title: Containers, Docker and Data Science
keywords: [containers, docker, data science, machine learning, data engineering]
index: 3
img: data-science-cover.png
---

Hardware virtualization and virtual machines were yesterday! Today is the age of containers. Just kidding, but containers are here to stay for a long time. 

{% include image.html url="/images/data-science-cover.png" description="source: https://upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Social_Network_Analysis_Visualization.png/1024px-Social_Network_Analysis_Visualization.png" %}

<blockquote>A container image is a lightweight, stand-alone, executable package of a piece of software that includes everything needed to run it: code, runtime, system tools, system libraries, settings. 
<cite>- https://www.docker.com/what-container</cite></blockquote>

Docker is one of the many providers to offer support through various tools like the Docker cli and Dockerhub evolving around the Dockerfile, very similar to Makefiles in their own domain. 
Container orchestration will not be part of this post. Kubernetes will be covered in later posts.

Now what can we do with it? Maybe create a small runtime for a data science workflow relying on programming languages like R and Python, having heavy dependencies on a lot of numerical optimization and statistical libraries as well as many adapters for several databases. In total you need about everything that you can think of as a full stack developer. It is a pain to get your dependencies correct, setting it up to solely work on models and algorithms describing your domain.


### Interesting Aspect

### Additional Information

### Papers, Journals and Books

### Tooling/Programming

### Examples

### Conclusion

### Sources

- [link1](https://google.com)
- [link2](https://google.com)
